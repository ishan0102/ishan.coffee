---
title: ML Links
date: 2023-10-22
tags:
  - seed
enableToc: false
---
- **Datasets**
  - [Kinetics-700](https://paperswithcode.com/dataset/kinetics-700)

- **Papers**
  - [DALL-E 3](https://cdn.openai.com/papers/dall-e-3.pdf)

- **Tutorials & Explainers**
  - [Predictions, Patterns, and Actions](http://mlstory.org)
  - [Karpathy's YouTube Playlist](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
  - [Transformers from Scratch](https://e2eml.school/transformers.html)
  - [GPT in 60 Lines](https://jaykmody.com/blog/gpt-from-scratch/)
  - [CUDA MatMul Kernel](https://siboehm.com/articles/22/CUDA-MMM)
  - [Autonomous AI Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)
  - [ML Interviews Book](https://huyenchip.com/ml-interviews-book/)
  - [Novice’s Guide to LLM Training](https://rentry.co/llm-training)
  - [Transformer Math](https://blog.eleuther.ai/transformer-math/#total-inference-memory)
  - [FlashAttention Explainer](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)
  - [Transformer Inference Arithmetic](https://kipp.ly/transformer-inference-arithmetic/)
  - [Kernel Cookbook](https://www.cs.toronto.edu/~duvenaud/cookbook/)
  - [Horace He Fast DL](https://horace.io/brrr_intro.html)
  - [Long Term Memory](http://augmentingcognition.com/ltm.html)
  - [Introduction to Kalman Filters for Programmers](https://praveshkoirala.com/2023/06/13/a-non-mathematical-introduction-to-kalman-filters-for-programmers/)
  - [Google’s Grokking Explainer](https://pair.withgoogle.com/explorables/grokking/)
  - [Understand Autodiff in 30 Lines](https://vmartin.fr/understanding-automatic-differentiation-in-30-lines-of-python.html)
  - [Little Book of Deep Learning](https://fleuret.org/public/lbdl.pdf)
  - [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
  - [The Bitter Lesson 2](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)
  - [Swyx's AI Notes](https://github.com/swyxio/ai-notes)
  - [Keeping up with AGI](https://docs.google.com/document/d/e/2PACX-1vQD8IlBotGdBxp3BnXkSjk8bNZlPV_0EH9ZA6wHd5dNf-BLSiwXUinvgv8ZoBEnNyTCF-chWO30NRw0/pub#h.gk70cijomli7)
  - https://kipp.ly/jul-aug-2023/
  - https://vgel.me/posts/handmade-transformer/
  - https://sumanthrh.com/post/distributed-and-efficient-finetuning/
  - stateof.ai

- **Projects & Models**
  - [Llama V2](https://nonint.com/)
    - [A16Z Infra Llama Chat](https://replicate.com/a16z-infra/llama-2-13b-chat)
    - [HF Model](https://huggingface.co/TheBloke/Llama-2-13B-GGML)
    - [Finetuning Tutorial](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)
  - [How is Llama Possible](https://finbarr.ca/how-is-llama-cpp-possible/)
  - [SAIL Courses](https://ai.stanford.edu/courses/)
  - [Stanford Smallville, Interactive Simulacra](https://github.com/joonspk-research/generative_agents)
