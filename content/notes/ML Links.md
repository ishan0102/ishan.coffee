---
title: ML Links
date: 2023-10-22
tags:
  - evergreen
enableToc: false
---
- [Predictions, Patterns, and Actions](http://mlstory.org)
- [Karpathy's YouTube Playlist](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
- [Transformers from Scratch](https://e2eml.school/transformers.html)
- [GPT in 60 Lines](https://jaykmody.com/blog/gpt-from-scratch/)
- [CUDA MatMul Kernel](https://siboehm.com/articles/22/CUDA-MMM)
- [Autonomous AI Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)
- [ML Interviews Book](https://huyenchip.com/ml-interviews-book/)
- [Novice’s Guide to LLM Training](https://rentry.co/llm-training)
- [Transformer Math](https://blog.eleuther.ai/transformer-math/#total-inference-memory)
- [FlashAttention Explainer](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad)
- [Transformer Inference Arithmetic](https://kipp.ly/transformer-inference-arithmetic/)
- [Kernel Cookbook](https://www.cs.toronto.edu/~duvenaud/cookbook/)
- [Horace He Fast DL](https://horace.io/brrr_intro.html)
- [Long Term Memory](http://augmentingcognition.com/ltm.html)
- [Introduction to Kalman Filters for Programmers](https://praveshkoirala.com/2023/06/13/a-non-mathematical-introduction-to-kalman-filters-for-programmers/)
- [Google’s Grokking Explainer](https://pair.withgoogle.com/explorables/grokking/)
- [Understand Autodiff in 30 Lines](https://vmartin.fr/understanding-automatic-differentiation-in-30-lines-of-python.html)
- [Little Book of Deep Learning](https://fleuret.org/public/lbdl.pdf)
- [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
- [The Bitter Lesson 2](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)
- [Swyx's AI Notes](https://github.com/swyxio/ai-notes)
- [Keeping up with AGI](https://docs.google.com/document/d/e/2PACX-1vQD8IlBotGdBxp3BnXkSjk8bNZlPV_0EH9ZA6wHd5dNf-BLSiwXUinvgv8ZoBEnNyTCF-chWO30NRw0/pub#h.gk70cijomli7)
- [Kipply's July-August Reading List](https://kipp.ly/jul-aug-2023/)
- [Handmade Transformer](https://vgel.me/posts/handmade-transformer/)
- [Distributed and Efficient Finetuning](https://sumanthrh.com/post/distributed-and-efficient-finetuning/)
- [stateof.ai](https://stateof.ai)
- [Machine Learning Flashcards](https://machinelearningflashcards.com/)
- [Kinetics-700](https://paperswithcode.com/dataset/kinetics-700)
- [DALL-E 3](https://cdn.openai.com/papers/dall-e-3.pdf)
- [Llama V2](https://nonint.com/)
- [A16Z Infra Llama Chat](https://replicate.com/a16z-infra/llama-2-13b-chat)
- [HF Model](https://huggingface.co/TheBloke/Llama-2-13B-GGML)
- [Finetuning Tutorial](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)
- [How is Llama Possible](https://finbarr.ca/how-is-llama-cpp-possible/)
- [SAIL Courses](https://ai.stanford.edu/courses/)
- [Stanford Smallville, Interactive Simulacra](https://github.com/joonspk-research/generative_agents)
- [OpenAI Cookbook](https://cookbook.openai.com/)
- [[Hardwae Resources](https://docs.google.com/document/d/1NCxdf9hTB1hFeRTvXOV0Pce4Yh7AFl2JuQhMyOQ4EjE)re Resources](https://docs.google.com/document/d/1NCxdf9hTB1hFeRTvXOV0Pce4Yh7AFl2JuQhMyOQ4EjE/edit?usp=sharing)
- [RLHF Lit Review](https://www.interconnects.ai/p/rlhf-lit-review-1-and-missing-pieces)
- [Kipply’s September-October Reading List](https://kipp.ly/sept-oct-2023/)
- [Tracing Emergent Abilities](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)
- [Matrix Calculus for Deep Learning](https://arxiv.org/pdf/1802.01528.pdf)
- https://github.com/stas00/ml-engineering
- https://blog.briankitano.com/llama-from-scratch/